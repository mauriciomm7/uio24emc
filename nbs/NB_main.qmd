---
title: "Lawmaking Coordination? Explaining Referral Failure in Federated Judicial Systems"
author: "Mauricio M. M."
date: 2024.07.17
description: This file documents the pipeline process from raw data into unit of analysis and unit of observation for the paper Lawmaking Coordination? Explaining Referral Failure in Federated Judicial Systems. This details the data collection and data aggregation process into units of analysis and units of observation. This is a draft document.
format: 
  html:
    theme: journal
    code-copy: true
    toc: true
    toc-location: right 
execute: 
    echo: true
    eval: true
html-math-method: mathjax
---

# NB1: Notebook created for scraping all the applications text from the ECJ

 **Output:** Clean dataset with the following variables. 

- [ ] `decision_date`: application date. 
- [ ] `referral_date `: date when the reference for preliminary referenc was sent. 
- [ ] `referring_court_name`: ???
- [ ] `ms_origin`: ???
- [ ] `num_applications`: def() construct from using `iuropa_all_cases_id` same for all apps.
- [ ] `full_text`: Full applications text that can be paresed into paragraphs and citations.
- [ ] `par_location`:
- [ ] `par_location_text`: 
- [ ] `cited_celex`:
- [ ] `cited_locations`:
- [ ] `cited_iuropa_id`: Code created using the constructor `A000P000L000`
- [ ] `num_questions`: def(max(par_locations)) unique for each app.
- [ ] `firts_referral`: def (sort_by(decision_date)) create bool flag.

**Output**: Create script that scrapes updates

## Environment and Settings Python

```{python}
# Required Libraries 
import os 
import sys
from bs4 import BeautifulSoup
import numpy as np
import pandas as pd
import altair as alt
import pyarrow.parquet as pq
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.metrics.pairwise import cosine_similarity

# Add project paths for for easier access across whole project
#paths_script_path = "C:\\Users\\mauricmm\\iCloudDrive\\cloudgit\\uio24emc\\"
parent_dir = os.path.dirname(os.getcwd(),) +"\\"
sys.path.append(parent_dir)
import paths
# Access paths globally
paths.figures_dir
```

```{python}
# def cool_function(x):

```

```{R}
# # Specify the file path
# file_path = "municipal_elections/oslo_fp.html"
# # Read HTML content from the file
# with open(file_path, 'r', encoding='UTF-8') as file:
#     html_content = file.read()

# # Parse the HTML content with BeautifulSoup
# soup = BeautifulSoup(html_content, 'html.parser')

# # Extract links using BeautifulSoup
# links = soup.select("table tr th a[href]")
# link_urls = [link['href'] for link in links]


```

## Environment and Settings R

```{r}
# LOAD Required libraries 
library(tidyr)
library(dplyr)
library(iuropa)
```


```{r}
#LOAD IUROPA DATA
session <- authenticate(
  username = "mmanriquez",
  password = "Xof6uf3STix2") # <- Create Session

check_authentication(session) # <- Check authentication
describe_components() # <- Describe Components IUROPA platform

```

```{r}
describe_tables(
  session=session,
  component = "cjeu_text_corpus") # <- Describe Tables in Component

describe_variables(
  session = session,
  component = "cjeu_text_corpus",
  table = "default")  #<- Describe Variables in Table 
```




### DAG Diagram

```{r}



```
