{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB3: Notebook created for processing judgment text\n",
    "\n",
    "**Output:** Clean dataset with the following variables. \n",
    "\n",
    "- [ ] `decision_date`: application date. \n",
    "- [ ] `referral_date `: date when the reference for preliminary referenc was sent. \n",
    "- [ ] `referring_court_name`: ???\n",
    "- [ ] `full_text`: \n",
    "- [ ] `par_location`:\n",
    "- [ ] \n",
    "\n",
    "**Output**: Create script that scrapes updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Settings for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED  Libraries\n",
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob \n",
    "#import pyarrow.parquet as pq\n",
    "#import pyarrow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ADD project paths for for easier access across whole project\n",
    "#paths_script_path = \"C:\\\\Users\\\\mauricmm\\\\iCloudDrive\\\\cloudgit\\\\uio24emc\\\\\"\n",
    "parent_dir = os.path.dirname(os.getcwd(),) +\"\\\\\"\n",
    "sys.path.append(parent_dir)\n",
    "import paths\n",
    "\n",
    "# Access paths globally\n",
    "paths.figures_dir\n",
    "# Import the functions from custom scripts\n",
    "from  costum_py import extract_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Processing Judgements Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#READ IUROPA Text Corpus Data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m iuropa_corpus_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mgitprojects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124muio24emc\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124miuropa_text.gz.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m iuropa_corpus \u001b[38;5;241m=\u001b[39m pq\u001b[38;5;241m.\u001b[39mread_table(iuropa_corpus_path)\n\u001b[0;32m      4\u001b[0m iuropa_corpus_df \u001b[38;5;241m=\u001b[39m iuropa_corpus\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[0;32m      5\u001b[0m schema \u001b[38;5;241m=\u001b[39m pq\u001b[38;5;241m.\u001b[39mread_schema(iuropa_corpus_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pq' is not defined"
     ]
    }
   ],
   "source": [
    "#READ IUROPA Text Corpus Data\n",
    "iuropa_corpus_path = \"C:\\\\gitprojects\\\\uio24emc\\\\raw\\\\iuropa_text.gz.parquet\"\n",
    "iuropa_corpus = pq.read_table(iuropa_corpus_path)\n",
    "iuropa_corpus_df = iuropa_corpus.to_pandas()\n",
    "schema = pq.read_schema(iuropa_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ ] CREATE columns selector \n",
    "# [ ] CREATE rows boolean mask\n",
    "# [ ] CHECK if the text from the sections is good  to process. \n",
    "# [ ] OUTPUT target dataset to to data as  \"judgements\" \n",
    "iuropa_corpus_df.columns\n",
    "\n",
    "\n",
    "# Columns selector Selector\n",
    "cols_selector =  ['document_id', 'paragraph_id', 'language', 'ecli', 'court',\n",
    "       'date', 'year', 'text', 'line_id', 'line_id_prop', 'section',\n",
    "       'paragraph_type', 'paragraph_number', 'nchar', 'html_class',\n",
    "       'html_attr']\n",
    "\n",
    "# BOOLEAN Conditions for mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iuropa_corpus_df.head()\n",
    "iuropa_corpus_df\n",
    "\n",
    "# Search for rows where the specified column contains the search text\n",
    "# This example performs a case-insensitive search\n",
    "limited_df = iuropa_corpus_df.head(1000)\n",
    "matching_rows = limited_df[limited_df['text'].str.contains( \"admissibility\" , case=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE Query for complex but not to elaborated queries\n",
    "filtered_df = df.query('description.str.contains(\"data\") & id > 1', engine='python')\n",
    "\n",
    "# USE BOOLEAN masks for more complex conditions\n",
    "condition1 = df['description'].str.contains('data', case=False, na=False)\n",
    "condition2 = df['age'] > 30\n",
    "condition3 = df['name'].isin(['Alice', 'David'])\n",
    "# Combine the conditions using logical operators\n",
    "complex_mask = condition1 & condition2 | condition3\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "filtered_df = df[complex_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB1 while it finishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# NB1 Applications Scaping\n",
    "#######################################\n",
    "# IGNORE replicatses data workiong with over there\n",
    "#######################################\n",
    "iu_uio24emc_dir = f\"{paths.raw_dir}iu_uio24emc\"\n",
    "## LOAD data for \n",
    "apps_ds = pd.read_csv(f\"{iu_uio24emc_dir}\\\\apps_scraping.csv\")\n",
    "## Subset for 2008-2023 \n",
    "apps_ds =apps_ds[apps_ds['eurlex_available']==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\gitprojects\\\\uio24emc\\\\raw\\\\appstxts\\\\ref_2008_0001it.txt', 'c:\\\\gitprojects\\\\uio24emc\\\\raw\\\\appstxts\\\\ref_2008_0002it.txt']\n"
     ]
    }
   ],
   "source": [
    "#SELECT folder path for easier writing filenames\n",
    "apps_txt_dir = f\"{paths.raw_dir}appstxts\"\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: c:\\gitprojects\\uio24emc\\raw\\appstxts\\ref_2008_0005dk.txt\n",
      "File already exists: c:\\gitprojects\\uio24emc\\raw\\appstxts\\ref_2008_0012be.txt\n",
      "File already exists: c:\\gitprojects\\uio24emc\\raw\\appstxts\\ref_2008_0013de.txt\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# PROCESSES Convert *.txt to clean *.txt\n",
    "#######################################\n",
    "#############################\n",
    "# OUTPUT ./raw dyad_apps_citations UoM Level \n",
    "# dyad_apps_text['referral_par_id'] = dyad_apps_text.apply(lambda row: f\"{row['uoa_dyad_id']}_PAR{str(row['par_num']).zfill(3)}\", axis=1)    :EX: REF_2010_0242IT_PAR01\n",
    "import html2text\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "#SELECT folder  path for easier file accessing \n",
    "apps_txt_dir = f\"{paths.raw_dir}appstxts\"\n",
    "\n",
    "all_txts_paths = glob.glob(f\"{apps_txt_dir}\\\\*.txt\")[0:20]\n",
    "\n",
    "#SELECT folder path for easier file wirting\n",
    "apps_clean_txt_dir = f\"{paths.raw_dir}cleanappstxt\"\n",
    "\n",
    "for txt_i in all_txts_paths:\n",
    "    #EXTRACT base file name and create clean file file name\n",
    "    basename = os.path.basename(txt_i)\n",
    "    out_path = f\"{apps_clean_txt_dir}\\\\{basename}\"\n",
    "    if os.path.exists(out_path):\n",
    "        print(f\"File already exists: {txt_i}\")\n",
    "    else:\n",
    "        #READ file path into current machine\n",
    "        with open(txt_i, \"r\", encoding=\"utf-8\") as in_file:\n",
    "            in_text_content = in_file.read()\n",
    "           #PARSE text into with html2text\n",
    "            h2t = html2text.HTML2Text()\n",
    "            h2t.ignore_links = True\n",
    "            out_text = h2t.handle(in_text_content)\n",
    "        # Write the parsed text to the output file\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(out_text)\n",
    "\n",
    "#######################\n",
    "# DONE Just copy paste to NB1\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i) |  Can the storing and subsequent printing out of a text extract from an article in a daily newspaper, consisting of a search word and the five preceding and five subsequent words, be regarded as acts of reproduction which are protected (see Article 2 of the Infosoc Directive (1))?  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "#FUNCTION Parse plain text to dataframe at 1DF UoM level\n",
    "#######################################\n",
    "#############################\n",
    "# OUTPUT ./raw/dyad_apps_text.csv UoM Level \n",
    "\n",
    "import html2text\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import re\n",
    "\n",
    "apps_clean_txt_dir = f\"{paths.raw_dir}cleanappstxt\"\n",
    "# Regular expression pattern to match the Markdown table\n",
    "table_pattern = r\"(\\|.*\\|(?:\\n\\|[-:]*\\|)+\\n(?:\\|.*\\|(?:\\n)?)*)\"\n",
    "\n",
    "doc1 = \"C:\\\\gitprojects\\\\uio24emc\\\\raw\\\\cleanappstxt\\\\ref_2008_0005dk.txt\"\n",
    "doc2 = \"C:\\\\gitprojects\\\\uio24emc\\\\raw\\\\cleanappstxt\\\\ref_2010_0240de.txt\"\n",
    "all_txts_paths = [doc1, doc2]\n",
    "\n",
    "\n",
    "for txt_i in all_txts_paths:\n",
    "    #KEY_ID column name and create clean file file name\n",
    "    uio_dyad_id = ((os.path.basename(txt_i))[:-4]).upper()\n",
    "    #LOAD file path into current machine as file\n",
    "    with open(txt_i, \"r\", encoding=\"utf-8\") as file:\n",
    "        #READ Lines\n",
    "        lines = file.readlines()\n",
    "        print(lines[27:])\n",
    "        data = []\n",
    "        \n",
    "    break\n",
    "\n",
    "\n",
    "################\n",
    "# ONCE table exists\n",
    "# CREATE Unique id \n",
    "# dyad_apps_text['referral_par_id'] = dyad_apps_text.apply(lambda row: f\"{row['uoa_dyad_id']}_PAR{str(row['par_num']).zfill(3)}\", axis=1)    :EX: REF_2010_0242IT_PAR01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No table found after the referred text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mauricmm\\AppData\\Local\\Temp\\ipykernel_13856\\163123204.py:19: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  referred_text = soup.find(text=text_regex)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# FUNCTION Beautiful soup extracts and puts into column\n",
    "####################################\n",
    "apps_ds =apps_ds[apps_ds['eurlex_available']==1]\n",
    "\n",
    "#In case you want to RE RUN IT\n",
    "baselink_txtonly =\"https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:\"\n",
    "text_regex = re.compile(r'Question(s)? referred', re.IGNORECASE)\n",
    "\n",
    "for index, row in apps_ds.iterrows():\n",
    "    dyad_id = row['uoa_dyad_id']\n",
    "    celex = str( row['apps_celex'])\n",
    "    baselink =\"https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=CELEX:\"\n",
    "    # Create the URL and filename dynamically using string formatting\n",
    "    url_i = f\"{baselink}{celex}\"\n",
    "    response = requests.get(url_i)\n",
    "    # Parse the webpage content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    referred_text = soup.find(text=text_regex)\n",
    "    # Initialize a variable to hold the table DataFrame\n",
    "    table_df = None\n",
    "    if referred_text:\n",
    "        # Find the next table after the found text\n",
    "        table = referred_text.find_next('table')\n",
    "        if table:\n",
    "            # Convert the table to a DataFrame\n",
    "            table_df = pd.read_html(str(table))[0]\n",
    "            # Save the table to a CSV file (optional)\n",
    "            table_df.to_csv('referred_question_table.csv', index=False)\n",
    "            \n",
    "            print('Extracted Table:\\n', table_df)\n",
    "        else:\n",
    "            print(\"No table found after the referred text.\")\n",
    "    else:\n",
    "        print(\"The specified text was not found on the page.\")\n",
    "        \n",
    "        # Optional: Save each table to a CSV file\n",
    "        break\n",
    "    break \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST extracting\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# FUNCTION Get celexes from apps\n",
    "#############################\n",
    "# OUTPUT ./raw dyad_apps_citations UoM Level \n",
    "# dyad_apps_citations['referral_par_id'] = dyad_apps_citations.apply(lambda row: f\"{row['uoa_dyad_id']}_PAR{str(row['par_num']).zfill(3)}\", axis=1)    :EX: REF_2010_0242IT_PAR01\n",
    "\n",
    "# Same as above h2t.ignore_links = False\n",
    "# extract celexes  \n",
    "\n",
    "#FUNCTION Fuzzy Match \n",
    "# Subset citations in c in C = XofC\n",
    "# ITERATE{ through every par \n",
    "# items =  \n",
    "# ITERATE{ through every citation match  if\n",
    "# Alternative is Create a citations lookup table with names and celexes \n",
    "# #####################################################\n",
    "# #######################################################\n",
    "#   #READ file content \n",
    "#         content = file.read()\n",
    "#     # Find the first Markdown table in the content\n",
    "#     match = re.search(table_pattern, content)\n",
    "#     if match:\n",
    "#         markdown_table = match.group(1)\n",
    "#         #df = pd.read_csv(pd.compat.StringIO(markdown_table), sep=\"|\", skipinitialspace=True)\n",
    "#     print(markdown_table)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML//EN\" \"xhtml-strict.dtd\">\n",
      "\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      "\n",
      "<!-- CONVEX # converter_version:3.2 # generated_on:20140122-2224 -->\n",
      "\n",
      "<head><meta name=\"format-detection\" content=\"telephone=no\"/>\n",
      "   <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/>\n",
      "   <script type=\"text/javascript\" src=\"/ruxitagentjs_ICANVfgqrux_10289240325103055.js\" data-dtconfig=\"app=47d4c64c3b67ec69|agentId=8a988541f17fe749|featureHash=ICANVfgqrux|rdnt=1|uxrgce=1|bp=3|cuc=m097nmfl|mel=100000|mb=null|dpvc=1|iub=null|ssv=4|lastModification=1723033979053|tp=500,50,0|agentUri=/ruxitagentjs_ICANVfgqrux_10289240325103055.js|reportUrl=/rb_39a3e95b-5423-482c-879b-99ef235dffeb|rid=RID_682125163|rpid=39833237|domain=europa.eu\"></script><link type=\"text/css\" rel=\"stylesheet\"\n",
      "         href=\"./../../../../css/oj/oj.css\"/>\n",
      "   <title>C_2008064EN.01002802.xml</title>\n",
      "<link rel=\"canonical\" href=\"https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A62008CN0005\"/>\n",
      "</head>\n",
      "<body>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"10%\"/>\n",
      "      <col width=\"10%\"/>\n",
      "      <col width=\"60%\"/>\n",
      "      <col width=\"20%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td>\n",
      "               <p class=\"hd-date\">8.3.2008   </p>\n",
      "            </td>\n",
      "            <td>\n",
      "               <p class=\"hd-lg\">EN</p>\n",
      "            </td>\n",
      "            <td>\n",
      "               <p class=\"hd-ti\">Official Journal of the European Union</p>\n",
      "            </td>\n",
      "            <td>\n",
      "               <p class=\"hd-oj\">C 64/28</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <hr class=\"separator\"/>\n",
      "   <p class=\"doc-ti\" id=\"d1e41-28-2\">Reference for a preliminary ruling from the Højesteret (Denmark) lodged on 4 January 2008 — Infopaq International A/S v Danske Dagblades Forening</p>\n",
      "   <p class=\"doc-ti\">(Case C-5/08)</p>\n",
      "   <p class=\"no-doc-c\">(2008/C 64/41)</p>\n",
      "   <p class=\"normal\">Language of the case: Danish</p>\n",
      "   <p id=\"d1e59-28-2\" class=\"ti-grseq-1\">Referring court</p>\n",
      "   <p class=\"normal\">Højesteret (Supreme Court)</p>\n",
      "   <p id=\"d1e66-28-2\" class=\"ti-grseq-1\">Parties to the main proceedings</p>\n",
      "   <p class=\"normal\">\n",
      "      <span class=\"italic\">Applicant:</span> Infopaq International A/S</p>\n",
      "   <p class=\"normal\">\n",
      "      <span class=\"italic\">Defendant:</span> Danske Dagblades Forening (Danish Daily Newspaper Publishers' Association)</p>\n",
      "   <p id=\"d1e79-28-2\" class=\"ti-grseq-1\">Questions referred</p>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(i)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Can the storing and subsequent printing out of a text extract from an article in a daily newspaper, consisting of a search word and the five preceding and five subsequent words, be regarded as acts of reproduction which are protected (see Article 2 of the Infosoc Directive<a id=\"ntc1-C_2008064EN.01002802-E0001\" href=\"#ntr1-C_2008064EN.01002802-E0001\"> (<span class=\"super\">1</span>)</a>)?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(ii)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Is the context in which temporary acts of reproduction take place relevant to whether they can be regarded as ‘transient’ (see Article 5(1) of the Infosoc Directive)?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(iii)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Can a temporary act of reproduction be regarded as ‘transient’ where the reproduction is processed, for example, by the creation of a text file on the basis of an image file or by a search for text strings on the basis of a text file?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(iv)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Can a temporary act of reproduction be regarded as ‘transient’ where part of the reproduction, consisting of one or more text extracts of 11 words, is stored?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(v)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Can a temporary act of reproduction be regarded as ‘transient’ where part of the reproduction, consisting of one or more text extracts of 11 words, is printed out?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(vi)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Is the stage of the technological process at which temporary acts of reproduction take place relevant to whether they constitute ‘an integral and essential part of a technological process’ (see Article 5(1) of the Infosoc Directive)?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(vii)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Can temporary acts of reproduction be an ‘integral and essential part of a technical process’ if they consist of manual scanning of entire newspaper articles whereby the latter are transformed from a printed medium into a digital medium?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(viii)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Can temporary acts of reproduction constitute an ‘integral and essential part of a technological process’ where they consist of printing out part of the reproduction, comprising one or more text extracts of 11 words?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(ix)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Does ‘lawful use’ (see Article 5(1) of the Infosoc Directive) include any form of use which does not require the copyright holder's consent?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(x)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Does ‘lawful use’ (see Article 5(1) of the Infosoc Directive) include the scanning by a commercial business of entire newspaper articles, subsequent processing of the reproduction, and the storing and possible printing out of part of the reproduction, consisting of one or more text extracts of 11 words, for use in the business's summary writing, even where the rightholder has not given consent to those acts?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(xi)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">What criteria should be used to assess whether temporary acts of reproduction have ‘independent economic significance’ (see Article 5(1) of the Infosoc Directive) if the other conditions laid down in the provision are satisfied?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(xii)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Can the user's efficiency gains from temporary acts of reproduction be taken into account in assessing whether the acts have ‘independent economic significance’ (see Article 5(1) of the Infosoc Directive)?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n",
      "      <col width=\"4%\"/>\n",
      "      <col width=\"96%\"/>\n",
      "      <tbody>\n",
      "         <tr>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">(xiii)</p>\n",
      "            </td>\n",
      "            <td valign=\"top\">\n",
      "               <p class=\"normal\">Can the scanning by a commercial business of entire newspaper articles, subsequent processing of the reproduction, and the storing and possible printing out of part of the reproduction, consisting of one or more text extracts of 11 words, without the rightholder's consent be regarded as constituting ‘certain special cases which do not conflict with a normal exploitation’ of the newspaper articles and ‘not unreasonably [prejudicing] the legitimate interests of the rightholder’ (see Article 5(5))?</p>\n",
      "            </td>\n",
      "         </tr>\n",
      "      </tbody>\n",
      "   </table>\n",
      "   <hr class=\"note\"/>\n",
      "   <p class=\"note\">\n",
      "      <a id=\"ntr1-C_2008064EN.01002802-E0001\" href=\"#ntc1-C_2008064EN.01002802-E0001\">(<span class=\"super\">1</span>)</a>  Directive 2001/29/EC of the European Parliament and of the Council of 22 May 2001 on the harmonisation of certain aspects of copyright and related rights in the information society (OJ L 167, p. 10).</p>\n",
      "   <hr class=\"doc-end\"/>\n",
      "</body>\n",
      "\n",
      "</html>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE might be useful\n",
    "# CREATE Unique id \n",
    "# dyad_apps_text['referral_par_id'] = dyad_apps_text.apply(lambda row: f\"{row['uoa_dyad_id']}_PAR{str(row['par_num']).zfill(3)}\", axis=1)    :EX: REF_2010_0242IT_PAR01\n",
    "\n",
    "# doc1 = \"C:\\\\gitprojects\\\\uio24emc\\\\raw\\\\appstxts\\\\ref_2008_0005dk.txt\"\n",
    "# with open(doc1, 'r') as file:\n",
    "#     # Read the entire content\n",
    "#     content = file.read()\n",
    "\n",
    "# # Print the content\n",
    "# print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
